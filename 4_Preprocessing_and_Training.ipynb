{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLJ1r5LTTZzT"
   },
   "source": [
    "# 4 Preprocessing and Training<a id='4_Preprocessing_and_Training'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GXZZFxhTZzZ"
   },
   "source": [
    "## 4.1 Contents<a id='4.1_Contents'></a>\n",
    "* [4 Preprocessing and Training](#4_Preprocessing_and_Training)\n",
    "  * [4.1 Contents](#4.1_Contents)\n",
    "  * [4.2 Introduction](#4.2_Introduction)\n",
    "  * [4.3 Imports](#4.3_Imports)\n",
    "  * [4.4 Load Data](#4.4_Load_Data)\n",
    "  * [4.5 Data Cleaning](#4.5_Data_Cleaning)\n",
    "      * [4.5.1 Drop columns from hold out set](#4.5.1_Drop_columns_from_hold_out_set)\n",
    "      * [4.5.2 Missing Values](#4.5.2_Missing_Values)\n",
    "  * [4.6 Split Dataset](#4.6_Split_Dataset)\n",
    "  * [4.7 Preprocessing](#4.7_Preprocessing)\n",
    "      * [4.7.1 Cadegorical Variable Cleaning](#4.7.1_Cadegorical_Variable_Cleaning)\n",
    "      * [4.7.2 Label Encoding](#4.7.2_Label_Encoding)\n",
    "      * [4.7.3 Train Test Split](#4.7.3_Train_Test_Split)\n",
    "      * [4.7.4 Scale the Data](#4.7.4_Scale_the_Data)\n",
    "      * [4.7.5 Balancing the Data](#4.7.5_Balancing_the_Data)\n",
    "  * [4.8 Save the Dataset](#4.8_Save_the_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cNOd1VmTZza"
   },
   "source": [
    "## 4.2 Introduction<a id='4.2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNSjmJaKTZza"
   },
   "source": [
    "In this notebook, I am going to first do some final data cleaning. Next, I will do preprocessing of categorical features and scaling of the data. Finally, I will break the training data into training and test splits to prepare for machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChugU8qiTZza"
   },
   "source": [
    "## 4.3 Imports<a id='4.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdvkTejvTZzb",
    "outputId": "62426dfd-75d8-4952-b234-511d82d58bad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import savetxt, where\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwIOYMMcTZzb"
   },
   "source": [
    "## 4.4 Load Data<a id='4.4_Load_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AZi26gXTZzc"
   },
   "source": [
    "In the previous notebook I saved the data as 'lc_step3.csv'. The hold-out dataset was saved in the data wrangling notebook as 'LC_2016_2017_cleaned.csv'. I will load this data now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PVc4zppqTZzc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lc_step3.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CjpHj_iQTZzc"
   },
   "outputs": [],
   "source": [
    "df_hold = pd.read_csv('LC_2016_2017_cleaned.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBd_4wnRTZzc"
   },
   "source": [
    "## 4.5 Data Cleaning<a id='4.5_Data_Cleaning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JdXK5Q5TZzd"
   },
   "source": [
    "Before preprocessing, I need to do some final data cleaning. I dropped a number of columns during EDA and now I am going to drop those from the hold-out set. Also, I did not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CmNXg0nTZzd"
   },
   "source": [
    "### 4.5.1 Drop columns from hold out set<a id='4.5.1_Drop_columns_from_hold_out_set'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoJpZ2KVTZzd",
    "outputId": "01541006-0bad-4a8b-8f83-b64c375f5448"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emp_length', 'loan_status', 'grade', 'term(months)']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df_hold.columns).difference(set(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7E75t7CTZze",
    "outputId": "16094eae-d7fe-406c-fbf6-5b576f36557e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758965, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the last notebook, I dropped a number of columns from the training set. Here I will drop those same columns\n",
    "# from the hold-out set.\n",
    "drop_col = ['grade', 'emp_length', 'loan_status', 'term(months)']\n",
    "df_hold.drop(drop_col, axis=1, inplace=True)\n",
    "df_hold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5JvM0wUTZzf"
   },
   "source": [
    "### 4.5.2 Missing Values<a id='4.5.2_Missing_Values'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpX1QTf-TZzf"
   },
   "source": [
    "Quick check to make sure there are no missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "aPvw8RhmTZzf",
    "outputId": "3a300d19-d2a3-420b-ace5-c977d10aec11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count    %\n",
       "loan_amnt                   0  0.0\n",
       "mths_since_last_record      0  0.0\n",
       "total_rev_hi_lim            0  0.0\n",
       "tot_coll_amt                0  0.0\n",
       "acc_now_delinq              0  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set missing values\n",
    "missing = pd.concat([df.isnull().sum(), 100 * df.isnull().mean()], axis=1)\n",
    "missing.columns=['count', '%']\n",
    "missing.sort_values(by='%', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "wdpWv08CTZzf",
    "outputId": "a429ae58-b588-40af-e955-503223080ef8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count    %\n",
       "loan_amnt                   0  0.0\n",
       "mths_since_last_record      0  0.0\n",
       "total_rev_hi_lim            0  0.0\n",
       "tot_coll_amt                0  0.0\n",
       "acc_now_delinq              0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_holdout = pd.concat([df_hold.isnull().sum(), 100 * df_hold.isnull().mean()], axis=1)\n",
    "missing_holdout.columns=['count', '%']\n",
    "missing_holdout.sort_values(by='%', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGYt3lwqTZzg"
   },
   "source": [
    "Good, there is no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HfFqB9jTZzg"
   },
   "source": [
    "## 4.6 Split Dataset<a id='4.6_Split_Dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v1saxWETZzg"
   },
   "source": [
    "df currently contains both the features and the targets (the 'defaults' column) for machine learning. I will need to seperate these before moving forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3RrFVZCLTZzg"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into features and target\n",
    "X = df.drop('defaults', axis=1)\n",
    "y = df['defaults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T0AvS1s2TZzg"
   },
   "outputs": [],
   "source": [
    "X_hold = df_hold.drop('defaults', axis=1)\n",
    "y_hold = df_hold['defaults']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfxC-qu-TZzh"
   },
   "source": [
    "## 4.7 Preprocessing<a id='4.7_Preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rQXtom5TZzh"
   },
   "source": [
    "### 4.7.1 Cadegorical Variable Cleaning<a id='4.7.1_Cadegorical_Variable_Cleaning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUNwKJeeTZzh"
   },
   "source": [
    "The categorical columns are currently dtype object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "Us4XJJ_4TZzh",
    "outputId": "5e0e62e3-6b96-4cbd-eadb-6c47ce9ba880"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10149342</th>\n",
       "      <td>B2</td>\n",
       "      <td>OWN</td>\n",
       "      <td>Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>MI</td>\n",
       "      <td>Oct-1986</td>\n",
       "      <td>Dec-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159584</th>\n",
       "      <td>C1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Jan-2007</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159498</th>\n",
       "      <td>A2</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CT</td>\n",
       "      <td>Mar-1994</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139658</th>\n",
       "      <td>B5</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NM</td>\n",
       "      <td>Oct-1998</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159548</th>\n",
       "      <td>A5</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>FL</td>\n",
       "      <td>Mar-1998</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36371250</th>\n",
       "      <td>B5</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Sep-2004</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36441262</th>\n",
       "      <td>B5</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Verified</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Mar-1974</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36271333</th>\n",
       "      <td>D2</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>TN</td>\n",
       "      <td>Sep-2003</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36490806</th>\n",
       "      <td>E3</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>MA</td>\n",
       "      <td>Oct-2003</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36271262</th>\n",
       "      <td>B5</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>FL</td>\n",
       "      <td>Dec-2001</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816877 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sub_grade home_ownership  ... earliest_cr_line last_credit_pull_d\n",
       "id                                 ...                                    \n",
       "10149342        B2            OWN  ...         Oct-1986           Dec-2015\n",
       "10159584        C1           RENT  ...         Jan-2007           Jan-2016\n",
       "10159498        A2       MORTGAGE  ...         Mar-1994           Jan-2016\n",
       "10139658        B5           RENT  ...         Oct-1998           Jan-2016\n",
       "10159548        A5       MORTGAGE  ...         Mar-1998           Jan-2016\n",
       "...            ...            ...  ...              ...                ...\n",
       "36371250        B5           RENT  ...         Sep-2004           Jan-2016\n",
       "36441262        B5       MORTGAGE  ...         Mar-1974           Jan-2016\n",
       "36271333        D2           RENT  ...         Sep-2003           Jan-2016\n",
       "36490806        E3           RENT  ...         Oct-2003           Jan-2016\n",
       "36271262        B5           RENT  ...         Dec-2001           Jan-2016\n",
       "\n",
       "[816877 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y0tNvvLkTZzh"
   },
   "outputs": [],
   "source": [
    "# Extracting year from the Earliest Credit Line and Last Credit Pulled columns\n",
    "X['earliest_cr_line_year'] = X['earliest_cr_line'].str.slice(4, 8).astype('category')\n",
    "X['last_credit_pull_d_year'] = X['last_credit_pull_d'].str.slice(4, 8).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PCEuaAODTZzi"
   },
   "outputs": [],
   "source": [
    "X_hold['earliest_cr_line_year'] = X_hold['earliest_cr_line'].str.slice(4, 8).astype('category')\n",
    "X_hold['last_credit_pull_d_year'] = X_hold['last_credit_pull_d'].str.slice(4, 8).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y0W9rKSITZzi"
   },
   "outputs": [],
   "source": [
    "# drop the original date columns\n",
    "X.drop(['earliest_cr_line', 'last_credit_pull_d'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AuSARYdUTZzi"
   },
   "outputs": [],
   "source": [
    "X_hold.drop(['earliest_cr_line', 'last_credit_pull_d'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l5S1MBtzTZzi"
   },
   "outputs": [],
   "source": [
    "# change the object columns to category\n",
    "for col in ['sub_grade', 'home_ownership', 'verification_status', 'purpose', 'addr_state']:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UF0kAOWjTZzj"
   },
   "outputs": [],
   "source": [
    "for col in ['sub_grade', 'home_ownership', 'verification_status', 'purpose', 'addr_state']:\n",
    "    X_hold[col] = X_hold[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEtnn0pDTZzj"
   },
   "source": [
    "### 4.7.2 Label Encoding<a id='4.7.2_Label_Encoding'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "opjLrbooTZzj"
   },
   "outputs": [],
   "source": [
    "categories = ['sub_grade', 'home_ownership', 'verification_status', 'purpose','addr_state', 'earliest_cr_line_year', 'last_credit_pull_d_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I6u3ZKDCTZzj"
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "for col in categories:\n",
    "    X[col]= label_encoder.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "t92t3Tp3TZzj"
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "for col in categories:\n",
    "    X_hold[col]= label_encoder.fit_transform(X_hold[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "P-JHwDciTZzk",
    "outputId": "4f35f4dc-f998-4f0c-ac33-576869857b02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>earliest_cr_line_year</th>\n",
       "      <th>last_credit_pull_d_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10149342</th>\n",
       "      <td>27050.0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>885.46</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36638.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59900.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159584</th>\n",
       "      <td>9750.0</td>\n",
       "      <td>13.98</td>\n",
       "      <td>333.14</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7967.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159498</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>368.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13168.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61100.0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139658</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>13.53</td>\n",
       "      <td>407.40</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>16.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5572.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15386.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159548</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>476.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>16.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11431.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>15400.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt  int_rate  ...  earliest_cr_line_year  last_credit_pull_d_year\n",
       "id                             ...                                                \n",
       "10149342    27050.0     10.99  ...                     40                        3\n",
       "10159584     9750.0     13.98  ...                     61                        4\n",
       "10159498    12000.0      6.62  ...                     48                        4\n",
       "10139658    12000.0     13.53  ...                     52                        4\n",
       "10159548    15000.0      8.90  ...                     52                        4\n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wV0hchdVUeE"
   },
   "outputs": [],
   "source": [
    "X.to_csv('features.csv')\n",
    "y.to_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U85K0s45TZzk"
   },
   "source": [
    "### 4.7.3 Train Test Split<a id='4.7.3_Train_Test_Split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnd-yoqtTZzk"
   },
   "source": [
    "Here I am going to split my dataset into training and test sets. I will have two different sets. One with the one-hot encoded dummy features and one with label encoded categorical features. The test set size is going to be 30%. Since only about 5% of loans default, I will need to set the stratify parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-jYfxEE5TZzk"
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjnjuSybTZzk"
   },
   "source": [
    "### 4.7.4 Scale the Data<a id='4.7.4_Scale_the_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ocj6omRnTZzl"
   },
   "source": [
    "For ML, I plan on using trees and logistic regression. The tree based models will use the label encoded split and the logistic regression model will use the dummy split. These models do not assume that the data is a normal distribution. To scale the data, I am going to use a standard scaler just on the dummy split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8zbTGYfaTZzl"
   },
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "X = scale.fit_transform(X)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dalVVUvpTZzl"
   },
   "source": [
    "### 4.7.5 Balancing the Data<a id='4.7.5_Balancing_the_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm-PNGfwUZx7"
   },
   "source": [
    "Since the dataset only contains approximately 5% defaulted loans, the data needs to be balanced. I am going to use a combination of SMOTE to oversample the minority class and RandomUnderSampler to undersample the majority class to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QSLwws09TZzl"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIL5WXguTZzl",
    "outputId": "b331b832-08eb-4e9d-963d-d22ad45a9794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 546317, 1: 25496})\n"
     ]
    }
   ],
   "source": [
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xU8yXonWinzD"
   },
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8rU2Z4TTZzl",
    "outputId": "af055d83-ce40-4d1c-921b-449b370624a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 109262, 1: 54631})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzfrma3bTZzm"
   },
   "source": [
    "## 4.8 Save the Dataset<a id='4.8_Save_the_Dataset'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rFRaenE7TZzm"
   },
   "outputs": [],
   "source": [
    "# Save the data for use in the next modeling notebook\n",
    "savetxt('X_train.csv', X, delimiter=',')\n",
    "savetxt('y_train.csv', y, delimiter=',')\n",
    "savetxt('X_test.csv', X_test, delimiter=',')\n",
    "savetxt('y_test.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCueVIiDT2w8",
    "outputId": "4028f66d-685d-4807-e3e2-2c516c38ec35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: X_test.csv (deflated 85%)\n",
      "  adding: X_train.csv (deflated 82%)\n",
      "  adding: y_test.csv (deflated 99%)\n",
      "  adding: y_train.csv (deflated 100%)\n"
     ]
    }
   ],
   "source": [
    "! zip train_test.csv.zip *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWJo5rc1TZzm"
   },
   "outputs": [],
   "source": [
    "X_hold.to_csv('X_holdout.csv')\n",
    "y_hold.to_csv('y_holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHIhRy_Ucz8K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_Preprocessing_and_Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
